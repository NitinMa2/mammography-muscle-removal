{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Run this code to ensure you're working on the correct environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamesgan/opt/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.lib.npyio import save\n",
    "import math\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib\n",
    "\n",
    "# for images handling & manipulation\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage import measure\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import laplace\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the directory of our dataset\n",
    "DATASET_DIR = \"dataset/mias/all-mias/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_paths(directory):\n",
    "    \"\"\"\n",
    "    Stores the path to all the images in a directory.\n",
    "    \n",
    "    Parameters:\n",
    "        directory(str): The directory containing the images\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: A list of paths to the pgm images\n",
    "    \"\"\"\n",
    "    # to store the paths to all the images\n",
    "    image_paths = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        # specifying image formats\n",
    "        if filename.endswith(\".pgm\"):\n",
    "            image_paths.append(os.path.join(directory, filename))\n",
    "            \n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_as_np_array(img_path, rgb=False):\n",
    "    \"\"\"\n",
    "    Reads an image as a numpy array.\n",
    "    \n",
    "    Parameters:\n",
    "        img_path(str): Path to the image\n",
    "        rgb(bool): Whether the image should be converted to RGB. False by default.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Image as a numpy array\n",
    "    \"\"\"\n",
    "    if rgb:\n",
    "        return np.asarray(Image.open(img_path).convert('RGB'))\n",
    "    else:\n",
    "        return np.asarray(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the image paths\n",
    "image_paths = get_img_paths(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Performing some exploratory data analysis to understand the data at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 322\n",
      "Shape of image: (1024, 1024)\n",
      "Size of image: 1048576 elements\n"
     ]
    }
   ],
   "source": [
    "# output some basic stats\n",
    "print('No. of images:', len(image_paths))\n",
    "\n",
    "sample_img = read_img_as_np_array(image_paths[0])\n",
    "\n",
    "print('Shape of image:', sample_img.shape)\n",
    "print('Size of image:', sample_img.size, 'elements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img_info):\n",
    "    \"\"\"\n",
    "    Displays an image from the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        img_info(int|str): Either the number of the image or the path to the image\n",
    "    \n",
    "    Assumptions:\n",
    "        - We're working with only the MIAS dataset\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the input is neither an int nor a str\n",
    "    \"\"\"\n",
    "    if isinstance(img_info, str):\n",
    "            file_path = img_info\n",
    "    elif isinstance(img_info, int):\n",
    "        file_number = str(img_info).zfill(3)\n",
    "        file_name = \"mdb\" + file_number + \".pgm\"\n",
    "        file_path = DATASET_DIR + file_name\n",
    "    else:\n",
    "        raise ValueError('You must pass in either the image number or path.')\n",
    "\n",
    "    # open the image\n",
    "    img = Image.open(file_path)\n",
    "\n",
    "    # show the image\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rand_images_grid(image_paths, rows=5, cols=5):\n",
    "    \"\"\"\n",
    "    Displays images from a directory in a grid.\n",
    "    \n",
    "    Parameters:\n",
    "        image_paths(str): Directory containing images\n",
    "        rows(int): Number of rows in the grid. 5 by default.\n",
    "        cols(int): Number of columns in the grid. 5 by default.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(15,15))\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            rand_index = random.randrange(len(image_paths))\n",
    "            ax[i, j].axis('off')\n",
    "            ax[i, j].imshow(read_img_as_np_array(image_paths[rand_index], rgb=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display random dataset images in a grid \n",
    "display_rand_images_grid(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_align(img):\n",
    "    \"\"\"\n",
    "    Determines whether the breast is aligned to the right or left side of the image\n",
    "    by measuring the mean gray level of either half. Flips the image to the left if it\n",
    "    is right-aligned.\n",
    "    \n",
    "    Parameters:\n",
    "        img: The numpy array representing the image.\n",
    "    \n",
    "    Assumptions:\n",
    "        - The half of the image on which the majority of the breast region lies has a higher mean than the othe half\n",
    "        - The input image is LCC view\n",
    "    \n",
    "    Returns:\n",
    "        numpy array with the left aligned image.\n",
    "    \"\"\"\n",
    "    pixels = np.asarray(img)\n",
    "    if np.mean(pixels[0:256, 0:128]) < np.mean(pixels[0:256, 128:256]):\n",
    "        return pixels[:, ::-1]\n",
    "    return pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_contrast(img):\n",
    "    \"\"\"\n",
    "    Adjusts the contrast of the given image by a specific factor.\n",
    "    \n",
    "    Parameters:\n",
    "        img: PIL image to be adjusted\n",
    "    Assumptions:\n",
    "        None\n",
    "    Returns:\n",
    "        PIL image with the contrast adjusted.\n",
    "    \"\"\"\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    factor = 1#increase contrast\n",
    "    img = enhancer.enhance(factor)\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bar(img):\n",
    "    \"\"\"\n",
    "    Finds the width of the black bar on the left of the image by checking iteratively until a pixel whose value is greater than\n",
    "    the mean of the grey values of the image is found. Then crops the image to remove the bar.\n",
    "    \n",
    "    Parameters:\n",
    "        img: numpy array of the image to be adjusted\n",
    "    Assumptions:\n",
    "        - There is no blank space at the top of the image (not even 1px)\n",
    "        - The image is left-aligned\n",
    "        - The black bar is darker than the mean grey level of the image, and the pectoral muscle region is brighter.\n",
    "    Returns:\n",
    "        Numpy array of the cropped image\n",
    "    \"\"\"\n",
    "    width = 0 \n",
    "    while img[1, width] <= np.mean(img):\n",
    "        width += 1\n",
    "    return img[:, width:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_left_pixel(img):\n",
    "    \"\"\"\n",
    "    Approximately finds the top left pixel where the mammogram begins.\n",
    "    \n",
    "    Parameters:\n",
    "        img: The PIL image\n",
    "    \n",
    "    Assumptions:\n",
    "        - There is no blank space at the top of the image (not even 1px)\n",
    "        - We want to optimize for speed over precision\n",
    "        - The input image is LCC view\n",
    "    \n",
    "    Returns:\n",
    "        int: The x position where the mammogram approximately begins\n",
    "    \"\"\"\n",
    "    # get all the pixel values\n",
    "    px = img.load()\n",
    "    # loop through the pixels and read the value\n",
    "    # tip: using a step of 5 to speed up the iteration by 5x. Remove the step is precision is more important.\n",
    "    for x in range(0, img[0], 5):\n",
    "        # checking the pixel value against a threshold\n",
    "        if px[0, x] > 50:\n",
    "            return x\n",
    "\n",
    "def test_find_top_left_pixel():\n",
    "    \"\"\"\n",
    "    Runs the find_top_left_pixel() method and visualizes the results.\n",
    "    \"\"\"\n",
    "    # setting up the plot\n",
    "    rows = 3\n",
    "    cols = 3\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(15,15))\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # picking a random image (left-aligned)\n",
    "            img_num = random.randrange(0, len(image_paths)+1, 2)\n",
    "            file_number = str(img_num).zfill(3)\n",
    "            file_name = \"mdb\" + file_number + \".pgm\"\n",
    "            file_path = DATASET_DIR + file_name\n",
    "            \n",
    "            # open the image\n",
    "            img = Image.open(file_path)\n",
    "\n",
    "            # get the x value of the top-left pixel\n",
    "            x_pixel = find_top_left_pixel(img)\n",
    "\n",
    "            # plot a big box to visualize the pixel location \n",
    "            for a in range(30):\n",
    "                for b in range(30):\n",
    "                    img.putpixel((x_pixel+a,b), 255)\n",
    "\n",
    "            ax[i, j].axis(\"off\")\n",
    "            ax[i, j].set_title(str(file_number))\n",
    "            ax[i, j].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_find_top_left_pixel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    \"\"\"\n",
    "    Combines all of the above preprocessing steps together on a given image.\n",
    "    \n",
    "    Parameters:\n",
    "        img: PIL image to be adjusted\n",
    "    Assumptions:\n",
    "        - There is no blank space at the top of the image (not even 1px).\n",
    "        - We want to optimize for speed over precision.\n",
    "        - The input image is LCC view.\n",
    "        - The half of the image on which the majority of the breast region lies has a higher mean than the othe half.\n",
    "        \n",
    "    Returns:\n",
    "        PIL image ready for the level set algorithm.\n",
    "    \"\"\"\n",
    "    img = img.resize((256,256))\n",
    "    img = left_align(img)\n",
    "    img = remove_bar(img)\n",
    "    img = np.interp(img, [np.min(img), np.max(img)], [0, 255])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_params(preprocessed_img):\n",
    "    \"\"\"\n",
    "    Return a dictionary containing all the parameters needed for the algorithm.\n",
    "    :param preprocessed_img: Input image that has been preprocessed. It will be passed as a parameter \n",
    "    to the level set algorithm\n",
    "    \"\"\"\n",
    "    # initialize LSF as binary step function\n",
    "    c0 = 2\n",
    "    initial_lsf = c0 * np.ones(preprocessed_img.shape)\n",
    "    # generate the initial region R0 as two rectangles\n",
    "    initial_lsf[0:10, 0:10] = -c0 # top left corner\n",
    "\n",
    "    # parameters\n",
    "    return {\n",
    "        'img': preprocessed_img,\n",
    "        'initial_lsf': initial_lsf,\n",
    "        'timestep': 7,  # time step\n",
    "        'iter_inner': 15,\n",
    "        'iter_outer': 45, # TEST: [30, 35, 45]\n",
    "        'lmda': 5.5,  # coefficient of the weighted length term L(phi)\n",
    "        'alfa': -3.5,  # coefficient of the weighted area term A(phi)\n",
    "        'epsilon': 1.2,  # parameter that specifies the width of the DiracDelta function -> 1.4\n",
    "        'sigma': 0.4,  # scale parameter in Gaussian kernel TEST: [0.4, 0.55, 0.7]\n",
    "        'potential_function': DOUBLE_WELL,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use single well potential p1(s)=0.5*(s-1)^2, which is good for region-based model\n",
    "DOUBLE_WELL = 'double-well'\n",
    "\n",
    "# use double-well potential in Eq. (16), which is good for both edge and region based models\n",
    "SINGLE_WELL = 'single-well'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that runs the DLRSE algorithm {iter_outer} times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lsf(img: np.ndarray, initial_lsf: np.ndarray, timestep=1, iter_inner=10, iter_outer=30, lmda=5,\n",
    "             alfa=-3, epsilon=1.5, sigma=0.8, potential_function=DOUBLE_WELL):\n",
    "    \"\"\"\n",
    "    :param img: Input image as a grey scale uint8 array (0-255)\n",
    "    :param initial_lsf: Array as same size as the img that contains the seed points for the LSF.\n",
    "    :param timestep: Time Step\n",
    "    :param iter_inner: How many iterations to run drlse before showing the output\n",
    "    :param iter_outer: How many iterations to run the iter_inner\n",
    "    :param lmda: coefficient of the weighted length term L(phi)\n",
    "    :param alfa: coefficient of the weighted area term A(phi)\n",
    "    :param epsilon: parameter that specifies the width of the DiracDelta function\n",
    "    :param sigma: scale parameter in Gaussian kernal\n",
    "    :param potential_function: The potential function to use in drlse algorithm. Should be SINGLE_WELL or DOUBLE_WELL\n",
    "    \"\"\"\n",
    "    if len(img.shape) != 2:\n",
    "        raise Exception(\"Input image should be a gray scale one\")\n",
    "\n",
    "    if len(img.shape) != len(initial_lsf.shape):\n",
    "        raise Exception(\"Input image and the initial LSF should be in the same shape\")\n",
    "\n",
    "    if np.max(img) <= 1:\n",
    "        raise Exception(\"Please make sure the image data is in the range [0, 255]\")\n",
    "\n",
    "    # parameters\n",
    "    mu = 0.2 / timestep  # coefficient of the distance regularization term R(phi)\n",
    "\n",
    "    img = np.array(img, dtype='float32')\n",
    "    img_smooth = gaussian_filter(img, sigma)  # smooth image by Gaussian convolution\n",
    "    [Iy, Ix] = np.gradient(img_smooth)\n",
    "    f = np.square(Ix) + np.square(Iy)\n",
    "    g = 1 / (1 + f)  # edge indicator function.\n",
    "\n",
    "    # initialize LSF as binary step function\n",
    "    phi = initial_lsf.copy()\n",
    "\n",
    "#     show_fig1(phi)\n",
    "#     show_fig2(phi, img)\n",
    "\n",
    "    if potential_function != SINGLE_WELL:\n",
    "        potential_function = DOUBLE_WELL  # default choice of potential function\n",
    "\n",
    "    # start level set evolution\n",
    "    for n in range(iter_outer):# outer * iter\n",
    "        phi = drlse_edge(phi, g, lmda, mu, alfa, epsilon, timestep, iter_inner, potential_function)\n",
    "#         draw_all(phi, img)\n",
    "\n",
    "    # refine the zero level contour by further level set evolution with alfa=0\n",
    "    alfa = 0\n",
    "    iter_refine = 10\n",
    "    phi = drlse_edge(phi, g, lmda, mu, alfa, epsilon, timestep, iter_refine, potential_function)\n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLRSE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drlse_edge(phi_0, g, lmda, mu, alfa, epsilon, timestep, iters, potential_function):  # Updated Level Set Function\n",
    "    \"\"\"\n",
    "\n",
    "    :param phi_0: level set function to be updated by level set evolution\n",
    "    :param g: edge indicator function\n",
    "    :param lmda: weight of the weighted length term\n",
    "    :param mu: weight of distance regularization term\n",
    "    :param alfa: weight of the weighted area term\n",
    "    :param epsilon: width of Dirac Delta function\n",
    "    :param timestep: time step\n",
    "    :param iters: number of iterations\n",
    "    :param potential_function: choice of potential function in distance regularization term.\n",
    "%              As mentioned in the above paper, two choices are provided: potentialFunction='single-well' or\n",
    "%              potentialFunction='double-well', which correspond to the potential functions p1 (single-well)\n",
    "%              and p2 (double-well), respectively.\n",
    "    \"\"\"\n",
    "    phi = phi_0.copy()\n",
    "    [vy, vx] = np.gradient(g)\n",
    "    for k in range(iters):\n",
    "        phi = neumann_bound_cond(phi)\n",
    "        [phi_y, phi_x] = np.gradient(phi)\n",
    "        s = np.sqrt(np.square(phi_x) + np.square(phi_y))\n",
    "        delta = 1e-10\n",
    "        n_x = phi_x / (s + delta)  # add a small positive number to avoid division by zero\n",
    "        n_y = phi_y / (s + delta)\n",
    "        curvature = div(n_x, n_y)\n",
    "\n",
    "        if potential_function == SINGLE_WELL:\n",
    "            dist_reg_term = laplace(phi, mode='nearest') - curvature  # compute distance regularization term in equation (13) with the single-well potential p1.\n",
    "        elif potential_function == DOUBLE_WELL:\n",
    "            dist_reg_term = dist_reg_p2(phi)  # compute the distance regularization term in eqaution (13) with the double-well potential p2.\n",
    "        else:\n",
    "            raise Exception('Error: Wrong choice of potential function. Please input the string \"single-well\" or \"double-well\" in the drlse_edge function.')\n",
    "        dirac_phi = dirac(phi, epsilon)\n",
    "        area_term = dirac_phi * g  # balloon/pressure force\n",
    "        edge_term = dirac_phi * (vx * n_x + vy * n_y) + dirac_phi * g * curvature\n",
    "        phi += timestep * (mu * dist_reg_term + lmda * edge_term + alfa * area_term)\n",
    "    return phi\n",
    "\n",
    "\n",
    "def dist_reg_p2(phi):\n",
    "    \"\"\"\n",
    "        compute the distance regularization term with the double-well potential p2 in equation (16)\n",
    "    \"\"\"\n",
    "    [phi_y, phi_x] = np.gradient(phi)\n",
    "    s = np.sqrt(np.square(phi_x) + np.square(phi_y))\n",
    "    a = (s >= 0) & (s <= 1)\n",
    "    b = (s > 1)\n",
    "    ps = a * np.sin(2 * np.pi * s) / (2 * np.pi) + b * (s - 1)  # compute first order derivative of the double-well potential p2 in equation (16)\n",
    "    dps = ((ps != 0) * ps + (ps == 0)) / ((s != 0) * s + (s == 0))  # compute d_p(s)=p'(s)/s in equation (10). As s-->0, we have d_p(s)-->1 according to equation (18)\n",
    "    return div(dps * phi_x - phi_x, dps * phi_y - phi_y) + laplace(phi, mode='nearest')\n",
    "\n",
    "\n",
    "def div(nx: np.ndarray, ny: np.ndarray) -> np.ndarray:\n",
    "    [_, nxx] = np.gradient(nx)\n",
    "    [nyy, _] = np.gradient(ny)\n",
    "    return nxx + nyy\n",
    "\n",
    "\n",
    "def dirac(x: np.ndarray, sigma: np.ndarray) -> np.ndarray:\n",
    "    f = (1 / 2 / sigma) * (1 + np.cos(np.pi * x / sigma))\n",
    "    b = (x <= sigma) & (x >= -sigma)\n",
    "    return f * b\n",
    "\n",
    "\n",
    "def neumann_bound_cond(f):\n",
    "    \"\"\"\n",
    "        Make a function satisfy Neumann boundary condition\n",
    "    \"\"\"\n",
    "    g = f.copy()\n",
    "\n",
    "    g[np.ix_([0, -1], [0, -1])] = g[np.ix_([2, -3], [2, -3])]\n",
    "    g[np.ix_([0, -1]), 1:-1] = g[np.ix_([2, -3]), 1:-1]\n",
    "    g[1:-1, np.ix_([0, -1])] = g[1:-1, np.ix_([2, -3])]\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "fig1 = plt.figure(1)\n",
    "fig2 = plt.figure(2)\n",
    "\n",
    "\n",
    "def show_fig1(phi: np.ndarray):\n",
    "    \"\"\"\n",
    "    Visualise the changes of the level set function in 3 dimensionals.\n",
    "    \"\"\"\n",
    "    fig1.clf()\n",
    "    ax1 = fig1.add_subplot(111, projection='3d')\n",
    "    y, x = phi.shape\n",
    "    x = np.arange(0, x, 1)\n",
    "    y = np.arange(0, y, 1)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    ax1.plot_surface(X, Y, -phi, rstride=2, cstride=2, color='r', linewidth=0, alpha=0.6, antialiased=True)\n",
    "    ax1.contour(X, Y, phi, 0, colors='g', linewidths=2)\n",
    "\n",
    "\n",
    "def show_fig2(phi: np.ndarray, img: np.ndarray):\n",
    "    \"\"\"\n",
    "    Visualise the contour changes. \n",
    "    \"\"\"\n",
    "    fig2.clf()\n",
    "    contours = measure.find_contours(phi, 0)\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    ax2.imshow(img, interpolation='nearest', cmap=plt.get_cmap('gray'))\n",
    "    for n, contour in enumerate(contours):\n",
    "        ax2.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "\n",
    "\n",
    "def draw_all(phi: np.ndarray, img: np.ndarray, pause=0.3):\n",
    "    show_fig2(phi, img)\n",
    "    # uncomment the following line if you want to see the 3D gradient evolution\n",
    "#     show_fig1(phi)\n",
    "    \n",
    "    plt.pause(pause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_segmented_image(phi: np.ndarray, img: np.ndarray):\n",
    "    \"\"\"\n",
    "    :params phi: finalised level set function (provide the boundary drawn)\n",
    "    :params img: img to be segmented\n",
    "    :params filename: file name used to save the image\n",
    "    \n",
    "    Assign the pixel within the boundary to be black. Save the output image. Return the segmented and original image for \n",
    "    visualisation purpose.\n",
    "    \"\"\"\n",
    "    original_img = img.copy()\n",
    "    contours = measure.find_contours(phi, 0)\n",
    "    max_of_y = int(np.round(max(contours[0], key=lambda x: x[0]))[0])\n",
    "    # contains the rightmost pixel at that particular y \n",
    "    record_array = [0] * (max_of_y + 1)\n",
    "    for contour in contours[0]:\n",
    "        x, y = int(contour[1]), round(contour[0]) \n",
    "        if record_array[y] < x:\n",
    "            record_array[y] = x\n",
    "    for i in range(len(record_array)):\n",
    "        for j in range(record_array[i]):\n",
    "            img[i,j] = 0\n",
    "    im = Image.fromarray(img)\n",
    "    im = im.convert('L')\n",
    "    im.save(\"output/segmented_\" + file_name)\n",
    "    return img, original_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_and_modified_photo_tuple_top_20 = [] # store a list of tuple, each tuple contains the numpy array \n",
    "                                         # of the original image and the modified image\n",
    "\n",
    "start = 1\n",
    "end = 21\n",
    "    \n",
    "for i in range(start,end):\n",
    "    file_number = str(i).zfill(3)\n",
    "    file_name = \"mdb\" + file_number + \".pgm\"\n",
    "    file_path = DATASET_DIR + file_name\n",
    "    img = Image.open(file_path)\n",
    "    contrasted_img = perform_contrast(img)\n",
    "    processed_img = preprocess_image(contrasted_img)\n",
    "    params = initialise_params(processed_img)\n",
    "    # params = two_cells_params()\n",
    "    phi = find_lsf(**params)\n",
    "    # print('Show final output')\n",
    "#     draw_all(phi, params['img']) # currently no pause\n",
    "\n",
    "    processed_img_for_download = preprocess_image(img)\n",
    "    img, original_img = save_segmented_image(phi, processed_img_for_download)\n",
    "    ori_and_modified_photo_tuple_top_20.append((original_img, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_counter = start\n",
    "counter = 0\n",
    "x_axis = 0\n",
    "\n",
    "fig, ax = plt.subplots(nrows=10,ncols=4, figsize=(15,12.5))\n",
    "fig.tight_layout()\n",
    "for original_img, img in ori_and_modified_photo_tuple_top_20:\n",
    "    y_axis= math.floor(counter)\n",
    "    ax[y_axis, x_axis].axis('off')\n",
    "    ax[y_axis, x_axis].imshow(original_img)\n",
    "    ax[y_axis, x_axis].set_title(\"mdb\" + str(id_counter) + \".pgm\", fontsize=10)\n",
    "    x_axis += 1\n",
    "    ax[y_axis, x_axis].axis('off')\n",
    "    ax[y_axis, x_axis].imshow(img)\n",
    "    ax[y_axis, x_axis].set_title(\"mdb\" + str(id_counter) + \".pgm\", fontsize=10)\n",
    "    id_counter+=1 \n",
    "    x_axis +=1 \n",
    "    if x_axis > 3:\n",
    "        x_axis = 0\n",
    "    counter += 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
